import gensim
from gensim.models import KeyedVectors
import os
import json
from difflib import SequenceMatcher

class WordSimilarityEngine:
    def __init__(self, database_path='word_database.json', ai_system=None):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å AI —Å–∏—Å—Ç–µ–º–æ–π"""
        self.model = None
        self.word_database = {}
        self.ai_system = ai_system
        
        self.load_database(database_path)
        self.load_model()
    
    def load_database(self, database_path):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –±–∞–∑—É —Å–ª–æ–≤"""
        if os.path.exists(database_path):
            print(f"üìñ –ó–∞–≥—Ä—É–∑–∫–∞ –±–∞–∑—ã —Å–ª–æ–≤...")
            with open(database_path, 'r', encoding='utf-8') as f:
                self.word_database = json.load(f)
            print(f"‚úì –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(self.word_database)} —Å–ª–æ–≤")
        else:
            print(f"‚ö†Ô∏è –ë–∞–∑–∞ —Å–ª–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
    
    def load_model(self):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç Word2Vec –º–æ–¥–µ–ª—å"""
        model_path = "ruscorpora_upos_skipgram_300_2_2019.bin"
        
        if os.path.exists(model_path):
            try:
                print("üì¶ –ó–∞–≥—Ä—É–∑–∫–∞ Word2Vec –º–æ–¥–µ–ª–∏...")
                self.model = KeyedVectors.load_word2vec_format(
                    model_path,
                    binary=True
                )
                print("‚úì Word2Vec –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞!")
            except Exception as e:
                print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e}")
                self.model = None
        else:
            print("‚ö†Ô∏è Word2Vec –º–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
            self.model = None
    
    def normalize_word(self, word: str) -> str:
        """–ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Å–ª–æ–≤–∞ —Å –∑–∞–º–µ–Ω–æ–π —ë ‚Üí –µ"""
        word = word.lower().strip()
        word = word.replace('—ë', '–µ')
        return word
    
    def validate_word(self, word: str) -> dict:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å —Å–ª–æ–≤–∞ —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π —ë/–µ"""
        word_normalized = self.normalize_word(word)
        
        if not word_normalized:
            return {"valid": False, "message": "–ü—É—Å—Ç–æ–µ —Å–ª–æ–≤–æ"}
        
        if word_normalized in self.word_database:
            return {"valid": True, "word": word_normalized}
        
        word_original = word.lower().strip()
        if word_original in self.word_database:
            return {"valid": True, "word": word_original}
        
        return {
            "valid": False,
            "message": f"–°–ª–æ–≤–æ '{word}' –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –≤ —Å–ª–æ–≤–∞—Ä–µ"
        }
    
    def get_synonyms(self, word: str, top_n: int = 20) -> list:
        """–ü–æ–ª—É—á–∞–µ—Ç —Å–∏–Ω–æ–Ω–∏–º—ã —á–µ—Ä–µ–∑ Word2Vec"""
        if not self.model:
            return []
        
        word = self.normalize_word(word)
        
        try:
            variants = [f"{word}_NOUN", f"{word}_ADJ", word]
            
            for variant in variants:
                if variant in self.model:
                    similar = self.model.most_similar(variant, topn=top_n)
                    synonyms = []
                    for w, score in similar:
                        clean_word = self.normalize_word(w.split('_')[0])
                        if clean_word in self.word_database and score > 0.4:
                            synonyms.append((clean_word, score))
                    return synonyms
            
            return []
        except Exception as e:
            return []
    
    def get_similarity(self, word1: str, word2: str) -> float:
        """–í—ã—á–∏—Å–ª—è–µ—Ç –ø–æ—Ö–æ–∂–µ—Å—Ç—å —Å —É–º–µ–Ω—å—à–µ–Ω–Ω—ã–º –≤–µ—Å–æ–º AI"""
        word1 = self.normalize_word(word1)
        word2 = self.normalize_word(word2)
        
        if word1 == word2:
            return 1.0
        
        similarities = []
        
        # 1. AI –æ–±—É—á–µ–Ω–∏–µ (15% –≤–µ—Å–∞)
        if self.ai_system:
            ai_sim = self.ai_system.get_learned_similarity(word1, word2)
            if ai_sim > 0:
                similarities.append(('ai', ai_sim, 0.15))
        
        # 2. Word2Vec (70% –≤–µ—Å–∞)
        if self.model:
            try:
                variants1 = [f"{word1}_NOUN", word1]
                variants2 = [f"{word2}_NOUN", word2]
                
                for v1 in variants1:
                    for v2 in variants2:
                        if v1 in self.model and v2 in self.model:
                            w2v_sim = float(self.model.similarity(v1, v2))
                            similarities.append(('w2v', w2v_sim, 0.70))
                            break
                    if similarities and similarities[-1][0] == 'w2v':
                        break
            except:
                pass
        
        # 3. –§–æ–Ω–µ—Ç–∏—á–µ—Å–∫–∞—è (15% –≤–µ—Å–∞)
        phonetic_sim = SequenceMatcher(None, word1, word2).ratio()
        similarities.append(('phonetic', phonetic_sim, 0.15))
        
        if similarities:
            total_weight = sum(w for _, _, w in similarities)
            weighted_sum = sum(sim * w for _, sim, w in similarities)
            final_similarity = weighted_sum / total_weight
            return min(final_similarity, 1.0)
        
        return 0.0
    
    def get_rank(self, guess_word: str, target_word: str) -> int:
        """–í—ã—á–∏—Å–ª—è–µ—Ç —Ä–∞–Ω–≥ –ë–ï–ó AI (–¥–ª—è –æ–¥–∏–Ω–∞–∫–æ–≤–æ–≥–æ —Ä–∞–Ω–≥–∞ —É –≤—Å–µ—Ö)"""
        guess_word = self.normalize_word(guess_word)
        target_word = self.normalize_word(target_word)
        
        if guess_word == target_word:
            return 0
        
        # –°–∏–Ω–æ–Ω–∏–º—ã —á–µ—Ä–µ–∑ Word2Vec
        synonyms = self.get_synonyms(target_word, top_n=100)
        for idx, (syn_word, score) in enumerate(synonyms):
            if syn_word == guess_word:
                rank = int(idx / score) + 1
                return min(rank, 200)
        
        # –ü–æ –ø–æ—Ö–æ–∂–µ—Å—Ç–∏
        similarity = self.get_similarity(guess_word, target_word)
        
        if similarity >= 0.85:
            return int((1 - similarity) * 200) + 10
        elif similarity >= 0.70:
            return int((1 - similarity) * 800) + 50
        elif similarity >= 0.55:
            return int((1 - similarity) * 2000) + 300
        elif similarity >= 0.40:
            return int((1 - similarity) * 5000) + 1200
        elif similarity >= 0.25:
            return int((1 - similarity) * 15000) + 4200
        elif similarity >= 0.10:
            return int((1 - similarity) * 30000) + 15700
        else:
            return int((1 - similarity) * 63000) + 36000
    
    def get_all_words(self) -> list:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≤—Å–µ —Å–ª–æ–≤–∞"""
        return list(self.word_database.keys())
    
    def get_word_info(self, word: str) -> dict:
        """–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Å–ª–æ–≤–µ"""
        word = self.normalize_word(word)
        return self.word_database.get(word, {})
